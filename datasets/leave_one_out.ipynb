{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping_item(item_id):\n",
    "    item_id = sorted(set(item_id))\n",
    "    item_id_mapping = dict()\n",
    "    for i in range(len(item_id)):\n",
    "        item_id_mapping[item_id[i]] = i\n",
    "    return item_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_format_data(data_set):\n",
    "    json_data = {}\n",
    "    key = data_set.keys()\n",
    "    for i in range(data_set.shape[0]):\n",
    "        row = data_set.iloc[i]\n",
    "        user, bundle = row[key[0]], row[key[1]]\n",
    "        if user not in json_data:\n",
    "            json_data[user] = []\n",
    "        json_data[user].append(bundle)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_txt(data_set, path):\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "    with open(path, 'a') as f:\n",
    "        for first_e in data_set:\n",
    "            for second_e in data_set[first_e]:\n",
    "                f.write(f'{first_e}\\t{second_e}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879\n",
      "218\n",
      "218\n",
      "965\n",
      "243\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "def split_leave_one_out(dataset_name):\n",
    "    user_bundle_path = os.path.join(dataset_name, \"user_bundle.csv\")\n",
    "    user_item_path = os.path.join(dataset_name, \"user_item.csv\")\n",
    "    bundle_item_path = os.path.join(dataset_name, \"bundle_item.csv\")\n",
    "    user_bundle = pd.read_csv(user_bundle_path)\n",
    "    user_item = pd.read_csv(user_item_path)\n",
    "    bundle_item = pd.read_csv(bundle_item_path)\n",
    "\n",
    "    item_id = []\n",
    "    for i in range(bundle_item.shape[0]):\n",
    "        item_id.append(bundle_item.iloc[i]['item ID'])\n",
    "    mapping_item_id = create_mapping_item(item_id)\n",
    "    # print(mapping_item_id)\n",
    "    # print(len(mapping_item_id))\n",
    "\n",
    "    bundle_item['item ID'] = bundle_item['item ID'].map(mapping_item_id)\n",
    "    user_item['item ID'] = user_item['item ID'].map(mapping_item_id)\n",
    "\n",
    "    user_bundle = user_bundle.drop(columns=['timestamp'])\n",
    "    ser_item = user_item.drop(columns=['timestamp'])\n",
    "\n",
    "    train_set = {}\n",
    "    test_set = {}\n",
    "    validation_set = {}\n",
    "    user_bundle_json = json_format_data(user_bundle)\n",
    "    for user in user_bundle_json:\n",
    "        if len(user_bundle_json[user]) < 3:\n",
    "            train_set[user] = user_bundle_json[user]\n",
    "        else:\n",
    "            train_set[user] = user_bundle_json[user][:-2]\n",
    "            validation_set[user] = [user_bundle_json[user][-2]]\n",
    "            test_set[user] = [user_bundle_json[user][-1]]\n",
    "    print(len(train_set)) # user for train\n",
    "    print(len(validation_set)) # user for validation\n",
    "    print(len(test_set)) # user for test\n",
    "\n",
    "    user_item = json_format_data(user_item)\n",
    "    bundle_item = json_format_data(bundle_item)\n",
    "\n",
    "    # path for output \n",
    "    bundle_item_output_path = os.path.join(dataset_name, \"bundle_item.txt\")\n",
    "    user_item_output_path = os.path.join(dataset_name, \"user_item.txt\")\n",
    "    user_bundle_item_train = os.path.join(dataset_name, \"user_bundle_train.txt\")\n",
    "    user_bundle_item_test = os.path.join(dataset_name, \"user_bundle_test.txt\")\n",
    "    user_bundle_item_tune = os.path.join(dataset_name, \"user_bundle_tune.txt\")\n",
    "\n",
    "    print_txt(train_set, user_bundle_item_train)\n",
    "    print_txt(validation_set, user_bundle_item_tune)\n",
    "    print_txt(test_set, user_bundle_item_test)\n",
    "    print_txt(user_item, user_item_output_path)\n",
    "    print_txt(bundle_item, bundle_item_output_path)\n",
    "\n",
    "dataset_name = ['food', 'clothing']\n",
    "for dataset in dataset_name:\n",
    "    split_leave_one_out(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
